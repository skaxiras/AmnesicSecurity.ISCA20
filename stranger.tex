\ignore{
\begin{verbatim}
Stranger Things go here for the moment 
until we figure out what to do with them.
\end{verbatim}
\redHL{U: Will embed this into the previous section where we talk about practical implementation.}
}

%\subsection{Impact on Coherence}
\subsection{Architectural Support for Slice Coherence}
\label{sec:coherence}
%Our {\recomp} approach for Delay-on-miss
ISER is based on the premise that we do not have to validate recomputed values: \emph{{\recomp} is not a speculation} (i.e., it is not a prediction). This is certainly the case for \emph{immutable} values that we can safely recompute instead of fetching them from the memory hierarchy. As long as the compiler guarantees via alias analysis that recomputed loads access \emph{immutable} values (from the time they were written by the corresponding producer), the approach is compatible with any consistency model and coherency protocol, simply because neither is needed to ensure correctness. We evaluate this case which, however, restricts {\recomp} coverage and limits the potential gains. Here, we discuss the potential of increasing coverage by relaxing the restrictions on slice formation.

The central question is what happens if we cannot statically ascertain the immutability of a load's value. 
In other words, what happens for values that we often recompute considering them immutable but there is a possibility, however small, that they can change by some unknown store. 
We will refer to such values as \emph{mostly-immutable}.\footnote{Naturally, we are not targeting \emph{mutable} values as successful {\recomp} would likely be much \emph{less} prevalent.}
%Compiler analysis can divide loads in three categories: \emph{no alias}, \emph{always alias}, and \emph{may alias}. Restricting our approach to recomputing 

For mostly-immutable values, we still want to maintain the essential property for our purposes, that {\recomp} is not a prediction that needs to be validated. Instead, what we want is to be able to make a simple binary decision: to recompute (if the value has not changed) or not (if the value has changed). In other words, we never validate {\recomp}, but we expect that a store would \emph{prevent} future recomputation of loads that would access the same address. 
%(See about consistency and ordering details in \autoref{sec:consistency} that follows.) 
This obviously implies that we must \emph{track} any possible change of the data that would be accessed by recomputed loads. We sketch here a possible approach but the actual mechanisms are beyond the scope of this paper.

For single-threaded applications,
%{\color{blue} such as the ones we study in this paper} {\color{red} [CHECKME: why? Is there a good justification for that?] -- CS: It's because we can't run multithreaded applications in Gem5, so I would avoid going into it here}, 
handling the recomputation of mostly-immutable values, implies a mechanism to match the thread's \emph{own} stores to the recomputed loads and invalidate the corresponding {\recomp} slices when such matches are found.\footnote{We assume, for the single-threaded case, that we would not recompute loads that touch I/O space that can be changed by a device without seeing any of our own stores modifying that space.}
%
To enable such a mechanism, the target address of the producer instruction %(e.g., store) 
is saved as a tag for the corresponding slice in the ISER structures. This tag can be matched by future stores on the same address, to invalidate the slice (and cancel recomputation) by invalidating, selectively or in bulk, ISER structures.
%are invalidated if a slice target address tag is matched by a future store (see \autoref{sec:coherence} and \autoref{sec:consistency}) as recomputation in this case can possibly produce an invalid (incoherent) result.
Since we expect this to be a rare occurrence (for what we choose to recompute), we can optimize for the case when it does not happen: Producer tags (store target addresses) can be encoded in signatures (Bloom filters) and 
%A Bloom filter encodes all the slice tags (target addresses) and 
if a future store hits in a signature, ISER structures and signatures are reset in bulk and need to be repopulated anew.
%See \autoref{sec:coherence} and \autoref{sec:consistency} for more details.

%\textcolor{blue}{HMS: What is needed is that the slice gets invalidated. The problem is that we have no way of guaranteeing that the slice exist in the IBuff, which would be the natural place to store this information. Another issue is how a slice becomes valid again once it has been invalidated.}
For multithreaded-applications, this matching and invalidation of recomputation slices should be expanded to include stores from other threads besides the thread's own stores. This requires an additional ``coherence'' mechanism to detect remote writes even when there is no copy of the relevant cacheline in the local cache. %While a detailed solution is outside the scope of this paper we sketch here a 
A solution can be based on an approach that serves a similar purpose: detecting remote writes in the absence of cached copies.
%and can be adapted for use in our particular situation. 

Specifically, the \emph{Callback} concept, introduced by Ros and Kaxiras~\cite{ros2015callback} can serve as the substrate on which to build a solution. A callback simply says ``notify me if someone writes on this address'' and it does not need cached copies that invite invalidations. Callback was introduced for synchronization, as an explicit \emph{request} for an invalidation in the absence of coherence invalidations (or more broadly absence of sharing). Callback can be generalized to perform a similar role in our situation with regards to detecting changes on what we would otherwise consider immutable values.
Similarly to the single-threaded case, tracked addresses can be encoded in signatures for efficient matching.
Security implications of using callbacks (such as perhaps new side-channels enabled by the callback directories~\cite{ros2016racer}) must also be addressed in the same way as in the work of Yan et al., SecDir~\cite{yan2019secdir}.
%Another similar approach would be to re-purpose the signature-based, race-detection hardware that sits at the level of the directory, proposed for an \emph{invalidation-less} coherence protocol by Ros and Kaxiras~\cite{ros2016racer}. Again the purpose would be the same: detect writes to mostly-immutable values that we would otherwise (wrongly) recompute.

To conclude, we argue that {\recomp} slices can be made \emph{coherent} by explicitly detecting changes to what we would consider immutable values. Techniques for explicitly detecting writes without invalidations have been proposed in prior work~\cite{ros2016racer,ros2015callback} and their adaptation to our purposes is feasible.

\subsection{Impact on Consistency}
\label{sec:consistency}
While the coherence approaches sketched above enable us to \emph{explicitly detect} changes in mostly-immutable values and \emph{invalidate} the corresponding {\recomp} slice, here, we discuss the order that this would need to happen in relation to the consistency model of the baseline architecture.
We use total store order (TSO) and release consistency ({\rc}) as our prime examples but our reasoning can be generalized to other consistency models. 
We use the term \emph{callback invalidation} to distinguish from the normal coherence invalidation, which may not be available when we have no cached copy of the corresponding data.
The question here is, once a change is detected to a value that we are capable of recomputing, when exactly is {\recomp} canceled? 

If {\recomp} occurs well in advance of the callback invalidation it is safe in any consistency model such as TSO or {\rc}. By ``well in advance'' we mean that the recomputed load is retired from the reorder buffer. In this case, it is as if the corresponding load has seen the \emph{old} value, well in advance of the change in the value. Once the callback invalidation reaches the core, there will be no further {\recomp} of that load.
Thus, we only need to clarify what happens when a callback invalidation and the corresponding {\recomp} occur in a critical window when consistency rules could be violated.

In {\rc}, {\recomp} is safe between memory fences. (RC, allows both loads and stores to be reordered, unless otherwise enforced by memory fences.) Callback invalidations received before an acquire memory fence must take hold and cancel {\recomp} before crossing the fence.

In TSO, load--load reordering is not allowed to be observed. A recomputed load is considered \emph{performed} as we consider it equivalent to accessing the actual data. In a \emph{speculative} implementation of TSO,  a recomputed load would be speculative with respect to an older load that is not performed. In other words, a recomputed load can be  in the M-Shadow of one or more older loads.
A callback invalidation reaching the core while a recomputed load is still under an M-Shadow (e.g., one or more older loads are still not-performed) should squash the recomputed load (and its dependents) and cancel further {\recomp}. 
%In this sense, the recomputed load is speculative (and is squashed) but not because it was recomputed, tried and failed a validation, but because it was out of order. 

% Alternatively, the recomputed value ca be irrevocably bound to an M-speculative load using the non-speculative load--load reordering approach proposed by Ros et al.~\cite{aros-isca17}. In this case, the recomputed load cannot be squashed simply because it is out of order with respect to older loads; it becomes non-speculative as long as it can set a \emph{lockdown} on the target address~\cite{aros-isca17} to delay conflicting remote stores until it retires.

To conclude, we argue that {\recomp} is compatible with both TSO and RC by observing a correct ordering between callback invalidations and {\recomp}.



%{\color{red} On TSO:
%RC seems to work wonders. This is because when we recompute,
%the result is by definition correct --- we do not verify.
%In this respect TSO is not violated by something that cannot change (see
%the ISCA'17 "Non-speculative Load-Load reordering in TSO").
%The situation is clear if the {\recomp} starts off from constants to
%compute a new value. The new value is immutable by other cores.
%That's what TSO wants.
%
%If the {\recomp} starts off from values loaded from the L1 (e.g.,
%hits) then we must make sure that these values do not change.
%But that's easy to do: we must ensure lock-downs (ISCA'17) for these
%loads. We can discuss how secure is that, but I believe we can claim
%that we can do RC that respects TSO even in this case. 
%
%When we use a real RC, the compiler detects the posibility of {\recomp} if all the inputs are constants (or pseudo-constant (write-once)?). In this case TSO is correct. The compiler is giving us the guarantee.
%
%The problem may come from 2 sources:
%
%- 1. The compiler does not know well (may-alias) if an input is constant.
%
%- 2. Parallel applications make it worse the first case.
%
%The idea could be to "predict at compiler time" no alias, and add ISCA'17 checks and guarantees at runtime.
%
%Right now, I would go for our current solution. In case of alias we do not recompute(we lose coverage), and we do not add speculation there. -- We can speculate in sw and fix it in hw for a follow up paper.
%
%Note: the compiler cannot guarantee DRF for x86 code, as the model is release consistency instead. 
%}

